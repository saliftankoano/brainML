{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5arxGsWxzec"
   },
   "source": [
    "# Streamlit web application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvophqnzxlKQ",
    "outputId": "4854d07d-649e-4b66-9a23-b1b924a5d702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.40.1)\n",
      "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install streamlit pyngrok python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MtFDH8-ex5ph"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from threading import Thread\n",
    "from pyngrok import ngrok\n",
    "from google.colab import userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmkS6m6fx95S"
   },
   "outputs": [],
   "source": [
    "ngrok_token = userdata.get('NGROK_AUTH_TOKEN')\n",
    "ngrok.set_auth_token(ngrok_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgQ8Bo6RyBP2"
   },
   "outputs": [],
   "source": [
    "def run_streamlit():\n",
    "  os.system('streamlit run /content/app.py --server.port 8501')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x5fwGP8SyEfJ",
    "outputId": "f0debdff-5723-4d90-d533-5d6339eee522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "import plotly.graph_objects as go\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.colab import userdata\n",
    "import PIL.Image\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "\n",
    "output_dir = 'saliency_maps'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def generate_explanations(img_path, model_prediction, confidence):\n",
    "  prompt = f\"\"\"You are an expert neurologist. You are tasked with explaining of explaining a saliency map of a brain MRI scan.\n",
    "  The saliency map was generated by a deep learning model that was trained to classify brain tumors as either glicoma meningioma, pituitary, or no tumor.\n",
    "  The saliency map highlights the regions of the image that the machine learning model is focusing on to make the prediction.\n",
    "  The deep learning model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100}%\n",
    "  In your response:\n",
    "  -Explain what regions of the brain the model is focusing on, based on the saliency map. Refer to the regions highlighted in light cyan\n",
    "  those are the regions that the model is focusing on.\n",
    "  - Explain why the model made this prediction\n",
    "  - Don't mention anything like 'the saliency map highlights the regions of the brain the model is focusing on, which are light cyan' in your response.\n",
    "  - Keep your reponse the 4 sentences max.\n",
    "\n",
    "  Let's think about this step by step. Verify step by step.\n",
    "  \"\"\"\n",
    "  img = PIL.Image.fromarray(img_path)\n",
    "\n",
    "  model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "  response = model.generate_content([prompt, img])\n",
    "\n",
    "  return response.text\n",
    "\n",
    "def generate_seliency_map(model, img_array, class_index, img_size):\n",
    "  with tf.GradientTape() as tape:\n",
    "    img_tensor = tf.convert_to_tensor(img_array)\n",
    "    tape.watch(img_tensor)\n",
    "    predictions = model(img_tensor)\n",
    "    target_class = predictions[:, class_index]\n",
    "  gradients = tape.gradient(target_class, img_tensor)\n",
    "  gradients = tf.math.abs(gradients)\n",
    "  gradients = tf.reduce_max(gradients, axis=-1)\n",
    "  gradients = gradients.numpy().squeeze()\n",
    "\n",
    "  # Resize gradients to match original image size\n",
    "  gradients = cv2.resize(gradients, img_size)\n",
    "\n",
    "  center = (gradients.shape[0] // 2 , gradients.shape[1] // 2)\n",
    "  radius = min(center[0], center[1]) - 10\n",
    "  y, x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]\n",
    "  mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2\n",
    "\n",
    "  # Apply mask to gradients\n",
    "  gradients = gradients * mask\n",
    "\n",
    "  # Normalize only the brain area\n",
    "  brain_gradients = gradients[mask]\n",
    "\n",
    "  if brain_gradients.max() > brain_gradients.min():\n",
    "    brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())\n",
    "  gradients[mask] = brain_gradients\n",
    "\n",
    "  # Apply a higher treshold\n",
    "  threshold = np.percentile(gradients[mask], 80)\n",
    "  gradients[gradients < threshold] = 0\n",
    "\n",
    "  # Apply a more aggresive soomthing\n",
    "  gradients = cv2.GaussianBlur(gradients, (11, 11), 0)\n",
    "\n",
    "  # Create a heatmap overlay with enhanced contrast\n",
    "  heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)\n",
    "  heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "  # Resize the heatmap\n",
    "  heatmap = cv2.resize(heatmap, img_size)\n",
    "\n",
    "  # Superimpose the heatmap on the original image with increased opacity\n",
    "  original_img = image.array_to_img(img)\n",
    "  original_img = np.array(original_img)\n",
    "  superimpose_img = heatmap * 0.7 + original_img * 0.3\n",
    "  superimpose_img = superimpose_img.astype(np.uint8)\n",
    "\n",
    "  img_path = os.path.join(output_dir, uploaded_file.name)\n",
    "  with open(img_path, 'wb') as f:\n",
    "    f.write(uploaded_file.getbuffer())\n",
    "  # Save the saliency map\n",
    "    saliency_map_path = os.path.join(output_dir, f\"saliency_{uploaded_file.name}\")\n",
    "    cv2.imwrite(saliency_map_path, cv2.cvtColor(superimpose_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "  return superimpose_img\n",
    "\n",
    "def load_xception_model(model_path):\n",
    "    image_shape = (299, 299, 3)\n",
    "    base_model = tf.keras.applications.Xception(\n",
    "        weights='imagenet',\n",
    "        input_shape=image_shape,\n",
    "        include_top=False,\n",
    "        pooling='max'\n",
    "    )\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(4, activation='softmax')\n",
    "    ])\n",
    "    model.build((None, )+ image_shape)\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adamax(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', Precision(), Recall()]\n",
    "    )\n",
    "\n",
    "    # Load weights\n",
    "    model.load_weights(model_path)\n",
    "    print(model.summary())  # To verify the architecture and layer shapes\n",
    "    return model\n",
    "st.title(\"Brain Tumor Classification\")\n",
    "st.write(\"Upload a Brain MRI Scan to classify\")\n",
    "uploaded_file = st.file_uploader(\"Choose a brain MRI ...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "\n",
    "  select_model = st.radio(\"Select model\", (\"Transfer Learning - Xception\", \"CNN\"))\n",
    "  if select_model == \"Transfer Learning - Xception\":\n",
    "    model = load_xception_model('/content/xception_model.weights.h5')\n",
    "    image_size = (299, 299)\n",
    "  else:\n",
    "    model = load_model('/content/cnn_model.keras')\n",
    "    image_size = (224, 224)\n",
    "\n",
    "  labels = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']\n",
    "  img = image.load_img(uploaded_file, target_size=image_size)\n",
    "  img_array = image.img_to_array(img)\n",
    "  img_array = np.expand_dims(img_array, axis=0)\n",
    "  img_array /= 255.0\n",
    "\n",
    "  prediction = model.predict(img_array)\n",
    "  class_index = np.argmax(prediction[0])\n",
    "  result = labels[class_index]\n",
    "\n",
    "  saliency_map_path = generate_seliency_map(model, img_array, class_index, image_size)\n",
    "\n",
    "  col1, col2 = st.columns(2)\n",
    "  with col1:\n",
    "    st.image(img, caption='Uploaded Image', use_container_width=True)\n",
    "  with col2:\n",
    "    st.image(saliency_map_path, caption='Saliency Map', use_container_width=True)\n",
    "\n",
    "  st.write(\"## Classification Results\")\n",
    "  result_container = st.container()\n",
    "  result_container = st.container()\n",
    "  result_container.markdown(\n",
    "      f\"\"\"\n",
    "      <div style=\"background-color: #000000; color: #ffffff; padding: 30px; border-radius: 15px;\">\n",
    "        <div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "          <div style=\"flex: 1; text-align: center;\">\n",
    "            <h3 style=\"color: #ffffff; margin-bottom: 10px; font-size: 20px;\">Prediction</h3>\n",
    "            <p style=\"color: #ff0000; font-size: 36px; font-weight: 800; margin: 0;\">\n",
    "              {result}\n",
    "            </p>\n",
    "          </div>\n",
    "          <div style=\"width: 2px; height: 80px; background-colort: #ffffff; margin: 0 20px;\"></div>\n",
    "          <div style=\"flex: 1; text-align: center;\">\n",
    "            <H3 style=\"color: #ffffff; margin-bottom: 10px; font-size: 20px;\">Confidence</h3>\n",
    "            <p style=\"color: #ff0000; font-size: 36px; font-weight: 800; margin: 0;\">\n",
    "              {prediction[0][class_index] * 100:.2f}%\n",
    "            </p>\n",
    "          </div>\n",
    "        </div>\n",
    "      </div>\n",
    "      \"\"\",\n",
    "      unsafe_allow_html=True\n",
    "  )\n",
    "\n",
    "  # Prepare data for Plotly chart\n",
    "  probabilities = prediction[0]\n",
    "  sorted_indices = np.argsort(probabilities)[::-1]\n",
    "  sorted_labels = [labels[i] for i in sorted_indices]\n",
    "  sorted_probabilities = probabilities[sorted_indices]\n",
    "\n",
    "  # Create a Plotly bar chart\n",
    "  fig = go.Figure(go.Bar(\n",
    "      x=sorted_probabilities,\n",
    "      y=sorted_labels,\n",
    "      orientation='h',\n",
    "      marker_color=['red' if label == result else 'blue' for label in sorted_labels]\n",
    "  ))\n",
    "\n",
    "  # Customize the chart layout\n",
    "  fig.update_layout(\n",
    "      title='Probabilities for each class',\n",
    "      xaxis_title='Probability',\n",
    "      yaxis_title='Class',\n",
    "      height=400,\n",
    "      width=600,\n",
    "      yaxis=dict(autorange='reversed')\n",
    "  )\n",
    "\n",
    "  # Add value labels to the bars\n",
    "  for i, prob in enumerate(sorted_probabilities):\n",
    "      fig.add_annotation(\n",
    "          x=prob,\n",
    "          y=i,\n",
    "          text=f'{prob:.4f}',\n",
    "          showarrow=False,\n",
    "          xanchor='left',\n",
    "          xshift=5\n",
    "      )\n",
    "\n",
    "  # Display the Plotly chart\n",
    "  st.plotly_chart(fig)\n",
    "\n",
    "  explanation = generate_explanations(saliency_map_path, result, prediction[0][class_index])\n",
    "  st.write(\"## Explanation\")\n",
    "  st.write(explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7UQtz0XyFOS"
   },
   "outputs": [],
   "source": [
    "thread = Thread(target=run_streamlit)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rw97OEMyG52",
    "outputId": "5869612a-72e2-4384-d94e-93dfb6f2a00c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public Url:  NgrokTunnel: \"https://86e9-35-237-13-208.ngrok-free.app\" -> \"http://localhost:8501\"\n"
     ]
    }
   ],
   "source": [
    "public_url = ngrok.connect(addr='8501', proto='http', bind_tls=True)\n",
    "print(\"Public Url: \",public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkOq4FtiyKzd"
   },
   "outputs": [],
   "source": [
    "tunnels = ngrok.get_tunnels()\n",
    "for tunnel in tunnels:\n",
    "  print(f\"Closing tunnel: {tunnel.public_url} -> {tunnel.config['addr']}\")\n",
    "  ngrok.disconnect(tunnel.public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gYE3K1scpnwL",
    "outputId": "be7143e5-3bd3-4e99-f271-d3074ceb47d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .env\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
